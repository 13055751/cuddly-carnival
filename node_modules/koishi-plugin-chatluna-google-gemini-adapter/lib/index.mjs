var __defProp = Object.defineProperty;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __name = (target, value) => __defProp(target, "name", { value, configurable: true });
var __commonJS = (cb, mod) => function __require() {
  return mod || (0, cb[__getOwnPropNames(cb)[0]])((mod = { exports: {} }).exports, mod), mod.exports;
};

// src/locales/zh-CN.schema.yml
var require_zh_CN_schema = __commonJS({
  "src/locales/zh-CN.schema.yml"(exports, module) {
    module.exports = { $inner: [{}, { $desc: "请求选项", platform: "适配器的平台名。（不懂请不要修改）", apiKeys: { $inner: ["Gemini 的 API Key", "Gemini API 的请求地址"], $desc: "Gemini 的 API Key 和请求地址列表。" } }, { $desc: "模型配置", maxTokens: "输入的最大上下文 Token（16~2097000，必须是 16 的倍数）。注意：仅当您使用的模型最大 Token 为 8000 及以上时，才建议设置超过 2000 token。", temperature: "回复的随机性程度，数值越高，回复越随机（范围：0~2）。", googleSearch: "为模型启用谷歌搜索。", thinkingBudget: "思考预算，范围：0~24576，设置的数值越大，思考时花费的 Token 越多。目前仅支持 gemini 2.5 系列模型。", groundingContentDisplay: "是否显示谷歌搜索结果。", imageGeneration: "为模型启用图像生成。目前仅支持 `gemini-2.0-flash-exp` 模型。", searchThreshold: "搜索的置信度阈值，范围：0~1，设置的数值越低，则越倾向于使用谷歌搜索。" }] };
  }
});

// src/locales/en-US.schema.yml
var require_en_US_schema = __commonJS({
  "src/locales/en-US.schema.yml"(exports, module) {
    module.exports = { $inner: [{}, { $desc: "API Configuration", platform: "Adapter platform name. (Do not modify if you do not understand)", apiKeys: { $inner: ["Gemini API Key", "Gemini API Endpoint (optional)"], $desc: "Gemini API access credentials" } }, { $desc: "Model Parameters", maxTokens: "Max output tokens (16-2097000, multiple of 16). >2000 for 8k+ models", temperature: "Sampling temperature (0-2). Higher: more random, Lower: more deterministic", googleSearch: "Enable Google search", thinkingBudget: "Thinking budget (0-24576). Higher: more tokens spent on thinking. Currently only supports `gemini-2.5` series models.", groundingContentDisplay: "Enable display of search results", imageGeneration: "Enable image generation (only for `gemini-2.0-flash-exp` model)", searchThreshold: "Search confidence [threshold](https://ai.google.dev/gemini-api/docs/grounding?lang=rest#dynamic-retrieval) (0-1). Lower: more likely to use Google search" }] };
  }
});

// src/index.ts
import { ChatLunaPlugin } from "koishi-plugin-chatluna/services/chat";
import { Schema } from "koishi";

// src/client.ts
import { PlatformModelAndEmbeddingsClient } from "koishi-plugin-chatluna/llm-core/platform/client";
import {
  ChatLunaChatModel,
  ChatLunaEmbeddings
} from "koishi-plugin-chatluna/llm-core/platform/model";
import {
  ModelType
} from "koishi-plugin-chatluna/llm-core/platform/types";
import {
  ChatLunaError as ChatLunaError2,
  ChatLunaErrorCode as ChatLunaErrorCode2
} from "koishi-plugin-chatluna/utils/error";

// src/requester.ts
import { AIMessageChunk as AIMessageChunk2 } from "@langchain/core/messages";
import { ChatGenerationChunk } from "@langchain/core/outputs";
import {
  ModelRequester
} from "koishi-plugin-chatluna/llm-core/platform/api";
import {
  ChatLunaError,
  ChatLunaErrorCode
} from "koishi-plugin-chatluna/utils/error";
import { checkResponse, sseIterable } from "koishi-plugin-chatluna/utils/sse";
import { readableStreamToAsyncIterable } from "koishi-plugin-chatluna/utils/stream";

// src/utils.ts
import {
  AIMessageChunk,
  ChatMessageChunk,
  HumanMessageChunk,
  SystemMessageChunk
} from "@langchain/core/messages";
import { zodToJsonSchema } from "zod-to-json-schema";
async function langchainMessageToGeminiMessage(messages, model) {
  const mappedMessage = await Promise.all(
    messages.map(async (rawMessage) => {
      const role = messageTypeToGeminiRole(rawMessage.getType());
      if (role === "function" || rawMessage.additional_kwargs?.function_call != null) {
        return {
          role: "function",
          parts: [
            {
              functionResponse: rawMessage.additional_kwargs?.function_call != null ? void 0 : {
                name: rawMessage.name,
                response: {
                  name: rawMessage.name,
                  content: (() => {
                    try {
                      const result3 = JSON.parse(
                        rawMessage.content
                      );
                      if (typeof result3 === "string") {
                        return {
                          response: result3
                        };
                      } else {
                        return result3;
                      }
                    } catch (e) {
                      return {
                        response: rawMessage.content
                      };
                    }
                  })()
                }
              },
              functionCall: rawMessage.additional_kwargs?.function_call != null ? {
                name: rawMessage.additional_kwargs.function_call.name,
                args: (() => {
                  try {
                    const result3 = JSON.parse(
                      rawMessage.additional_kwargs.function_call.arguments
                    );
                    if (typeof result3 === "string") {
                      return {
                        input: result3
                      };
                    } else {
                      return result3;
                    }
                  } catch (e) {
                    return {
                      input: rawMessage.additional_kwargs.function_call.arguments
                    };
                  }
                })()
              } : void 0
            }
          ]
        };
      }
      const images = rawMessage.additional_kwargs.images;
      const result2 = {
        role,
        parts: [
          {
            text: rawMessage.content
          }
        ]
      };
      if ((model.includes("vision") || model.includes("gemini") || model.includes("gemma")) && images != null && !model.includes("gemini-1.0")) {
        for (const image of images) {
          const mineType = image.split(";")?.[0]?.split(":")?.[1];
          const data = image.replace(/^data:image\/\w+;base64,/, "");
          result2.parts.push({
            inline_data: {
              // base64 image match type
              data,
              mime_type: mineType ?? "image/jpeg"
            }
          });
        }
        result2.parts = result2.parts.filter((uncheckedPart) => {
          const part = partAsTypeCheck(
            uncheckedPart,
            (part2) => part2["text"] != null
          );
          return part == null || part.text.length > 0;
        });
      }
      return result2;
    })
  );
  const result = [];
  for (let i = 0; i < mappedMessage.length; i++) {
    const message = mappedMessage[i];
    if (message.role !== "system") {
      result.push(message);
      continue;
    }
    result.push({
      role: "user",
      parts: message.parts
    });
    const nextMessage = mappedMessage?.[i + 1];
    if (nextMessage?.role === "model") {
      continue;
    }
    if (nextMessage?.role === "user" || nextMessage?.role === "system") {
      result.push({
        role: "model",
        parts: [{ text: "Okay, what do I need to do?" }]
      });
    }
    if (nextMessage?.role === "system") {
      result.push({
        role: "user",
        parts: [
          {
            text: "Continue what I said to you last message. Follow these instructions."
          }
        ]
      });
    }
  }
  if (result[result.length - 1].role === "model") {
    result.push({
      role: "user",
      parts: [
        {
          text: "Continue what I said to you last message. Follow these instructions."
        }
      ]
    });
  }
  return result;
}
__name(langchainMessageToGeminiMessage, "langchainMessageToGeminiMessage");
function partAsType(part) {
  return part;
}
__name(partAsType, "partAsType");
function partAsTypeCheck(part, check) {
  return check(part) ? part : void 0;
}
__name(partAsTypeCheck, "partAsTypeCheck");
function formatToolsToGeminiAITools(tools, config, model) {
  if (tools.length < 1 && !config.googleSearch) {
    return void 0;
  }
  const functions = tools.map(formatToolToGeminiAITool);
  const result = [];
  const unsupportedModels = [
    "gemini-1.0",
    "gemini-2.0-flash-lite",
    "gemini-1.5-flash",
    "gemini-2.0-flash-exp"
  ];
  const imageGenerationModels = [
    "gemini-2.0-flash-exp",
    "gemini-2.0-flash-exp-image-generation"
  ];
  let googleSearch = config.googleSearch;
  if (functions.length > 0 && !googleSearch) {
    result.push({
      functionDeclarations: functions
    });
  } else if (functions.length > 0 && googleSearch) {
    logger.warn("Google search is enabled, tool calling will be disable.");
  } else if ((unsupportedModels.some(
    (unsupportedModel) => model.includes(unsupportedModel)
  ) || imageGenerationModels.some(
    (unsupportedModels2) => model.includes(unsupportedModels2)
  ) && config.imageGeneration) && googleSearch) {
    logger.warn(
      `The model ${model} does not support google search. google search will be disable.`
    );
    googleSearch = false;
  }
  if (googleSearch) {
    if (model.includes("gemini-2")) {
      result.push({
        google_search: {}
      });
    } else {
      result.push({
        google_search_retrieval: {
          dynamic_retrieval_config: {
            mode: "MODE_DYNAMIC",
            dynamic_threshold: config.searchThreshold
          }
        }
      });
    }
  }
  return result;
}
__name(formatToolsToGeminiAITools, "formatToolsToGeminiAITools");
function formatToolToGeminiAITool(tool) {
  const parameters = removeAdditionalProperties(
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    zodToJsonSchema(tool.schema, {
      allowedAdditionalProperties: void 0
    })
  );
  return {
    name: tool.name,
    description: tool.description,
    // any?
    parameters
  };
}
__name(formatToolToGeminiAITool, "formatToolToGeminiAITool");
function removeAdditionalProperties(schema) {
  if (!schema || typeof schema !== "object") return schema;
  const stack = [[schema, null]];
  while (stack.length > 0) {
    const [current] = stack.pop();
    if (typeof current !== "object" || current === null) continue;
    if (Object.hasOwn(current, "additionalProperties")) {
      delete current["additionalProperties"];
    }
    if (Object.hasOwn(current, "$schema")) {
      delete current["$schema"];
    }
    for (const key of Object.keys(current)) {
      const value = current[key];
      if (value && typeof value === "object") {
        stack.push([value, key]);
      }
    }
  }
  return schema;
}
__name(removeAdditionalProperties, "removeAdditionalProperties");
function messageTypeToGeminiRole(type) {
  switch (type) {
    case "system":
      return "system";
    case "ai":
      return "model";
    case "human":
      return "user";
    case "function":
      return "function";
    default:
      throw new Error(`Unknown message type: ${type}`);
  }
}
__name(messageTypeToGeminiRole, "messageTypeToGeminiRole");

// src/requester.ts
import fs from "fs/promises";
var GeminiRequester = class extends ModelRequester {
  constructor(_config, _plugin, _pluginConfig) {
    super();
    this._config = _config;
    this._plugin = _plugin;
    this._pluginConfig = _pluginConfig;
  }
  static {
    __name(this, "GeminiRequester");
  }
  async *completionStream(params) {
    try {
      let model = params.model;
      let enabledThinking = null;
      if (model.includes("-thinking") && model.includes("gemini-2.5")) {
        enabledThinking = !model.includes("-no-thinking");
        model = model.replace("-no-thinking", "").replace("-thinking", "");
      }
      const response = await this._post(
        `models/${model}:streamGenerateContent?alt=sse`,
        {
          contents: await langchainMessageToGeminiMessage(
            params.input,
            model
          ),
          safetySettings: [
            {
              category: "HARM_CATEGORY_HARASSMENT",
              threshold: params.model.includes("gemini-2") ? "OFF" : "BLOCK_NONE"
            },
            {
              category: "HARM_CATEGORY_HATE_SPEECH",
              threshold: params.model.includes("gemini-2") ? "OFF" : "BLOCK_NONE"
            },
            {
              category: "HARM_CATEGORY_SEXUALLY_EXPLICIT",
              threshold: params.model.includes("gemini-2") ? "OFF" : "BLOCK_NONE"
            },
            {
              category: "HARM_CATEGORY_DANGEROUS_CONTENT",
              threshold: params.model.includes("gemini-2") ? "OFF" : "BLOCK_NONE"
            },
            {
              category: "HARM_CATEGORY_CIVIC_INTEGRITY",
              threshold: params.model.includes("gemini-2.0") ? "OFF" : "BLOCK_NONE"
            }
          ],
          generationConfig: {
            stopSequences: params.stop,
            temperature: params.temperature,
            maxOutputTokens: params.model.includes("vision") ? void 0 : params.maxTokens,
            topP: params.topP,
            responseModalities: params.model.includes(
              // TODO: Wait for google release to all models
              "gemini-2.0-flash-exp"
            ) && this._pluginConfig.imageGeneration ? ["TEXT", "IMAGE"] : void 0,
            thinkingConfig: enabledThinking != null ? {
              thinkingBudget: enabledThinking ? this._pluginConfig.thinkingBudget ?? 4096 : 0
              // includeThoughts: true
            } : void 0
          },
          tools: params.tools != null || this._pluginConfig.googleSearch ? formatToolsToGeminiAITools(
            params.tools ?? [],
            this._pluginConfig,
            params.model
          ) : void 0
        },
        {
          signal: params.signal
        }
      );
      let errorCount = 0;
      let groundingContent = "";
      let currentGroudingIndex = 0;
      await checkResponse(response);
      const readableStream = new ReadableStream({
        async start(controller) {
          for await (const chunk of sseIterable(response)) {
            controller.enqueue(chunk.data);
          }
          controller.close();
        }
      });
      const transformToChatPartStream = new TransformStream({
        async transform(chunk, controller) {
          const parsedValue = JSON.parse(chunk);
          const transformValue = parsedValue;
          if (!transformValue.candidates) {
            return;
          }
          for (const candidate of transformValue.candidates) {
            const parts = candidate.content?.parts;
            if ((parts == null || parts.length < 1) && candidate.finishReason !== "STOP") {
              throw new Error(chunk);
            } else if (candidate.finishReason === "STOP" && parts == null) {
              continue;
            }
            for (const part of parts) {
              controller.enqueue(part);
            }
            for (const source of candidate.groundingMetadata?.groundingChunks ?? []) {
              groundingContent += `[^${currentGroudingIndex++}]: [${source.web.title}](${source.web.uri})
`;
            }
          }
        }
      });
      const iterable = readableStreamToAsyncIterable(
        readableStream.pipeThrough(transformToChatPartStream)
      );
      let reasoningContent = "";
      let content = "";
      const functionCall = {
        name: "",
        args: "",
        arguments: ""
      };
      for await (const chunk of iterable) {
        const messagePart = partAsType(chunk);
        const chatFunctionCallingPart = partAsType(chunk);
        const imagePart = partAsTypeCheck(
          chunk,
          (part) => part["inlineData"] != null
        );
        if (messagePart.text) {
          if (messagePart.thought) {
            reasoningContent += messagePart.text;
            continue;
          }
          content = messagePart.text;
        } else if (imagePart) {
          messagePart.text = `![image](data:${imagePart.inlineData.mimeType ?? "image/png"};base64,${imagePart.inlineData.data})`;
          content = messagePart.text;
        }
        const deltaFunctionCall = chatFunctionCallingPart?.functionCall;
        if (deltaFunctionCall) {
          let args = deltaFunctionCall.args?.input ?? deltaFunctionCall.args;
          try {
            let parsedArgs = JSON.parse(args);
            if (typeof parsedArgs !== "string") {
              args = parsedArgs;
            }
            parsedArgs = JSON.parse(args);
            if (typeof parsedArgs !== "string") {
              args = parsedArgs;
            }
          } catch (e) {
          }
          functionCall.args = JSON.stringify(args);
          functionCall.name = deltaFunctionCall.name;
          functionCall.arguments = deltaFunctionCall.args;
        }
        try {
          const messageChunk = new AIMessageChunk2(content);
          messageChunk.additional_kwargs = {
            function_call: functionCall.name.length > 0 ? {
              name: functionCall.name,
              arguments: functionCall.args,
              args: functionCall.arguments
            } : void 0,
            images: imagePart ? [
              `data:${imagePart.inlineData.mimeType ?? "image/png"};base64,${imagePart.inlineData.data}`
            ] : void 0
            // eslint-disable-next-line @typescript-eslint/no-explicit-any
          };
          messageChunk.content = content;
          const generationChunk = new ChatGenerationChunk({
            message: messageChunk,
            text: messageChunk.content
          });
          yield generationChunk;
          content = messageChunk.content;
        } catch (e) {
          if (errorCount > 5) {
            logger.error("error with chunk", chunk);
            throw new ChatLunaError(
              ChatLunaErrorCode.API_REQUEST_FAILED,
              e
            );
          } else {
            errorCount++;
            continue;
          }
        }
      }
      if (reasoningContent.length > 0) {
        logger.debug(`reasoning content: ${reasoningContent}`);
      }
      if (groundingContent.length > 0) {
        logger.debug(`grounding content: ${groundingContent}`);
        if (this._pluginConfig.groundingContentDisplay) {
          const groundingMessage = new AIMessageChunk2(
            `
${groundingContent}`
          );
          const generationChunk = new ChatGenerationChunk({
            message: groundingMessage,
            text: "\n" + groundingContent
          });
          yield generationChunk;
        }
      }
    } catch (e) {
      if (e instanceof ChatLunaError) {
        throw e;
      } else {
        throw new ChatLunaError(ChatLunaErrorCode.API_REQUEST_FAILED, e);
      }
    }
  }
  async embeddings(params) {
    let data;
    if (typeof params.input === "string") {
      params.input = [params.input];
    }
    try {
      const response = await this._post(
        `models/${params.model}:batchEmbedContents`,
        {
          requests: params.input.map((input) => {
            return {
              model: `models/${params.model}`,
              content: {
                parts: [
                  {
                    text: input
                  }
                ]
              }
            };
          })
        }
      );
      data = await response.text();
      data = JSON.parse(data);
      if (data.embeddings && data.embeddings.length > 0) {
        return data.embeddings.map((embedding) => {
          return embedding.values;
        });
      }
      throw new Error(
        "error when calling gemini embeddings, Result: " + JSON.stringify(data)
      );
    } catch (e) {
      const error = new Error(
        "error when calling gemini embeddings, Result: " + JSON.stringify(data)
      );
      error.stack = e.stack;
      error.cause = e.cause;
      logger.debug(e);
      throw new ChatLunaError(ChatLunaErrorCode.API_REQUEST_FAILED, error);
    }
  }
  async getModels() {
    let data;
    try {
      const response = await this._get("models");
      data = await response.text();
      data = JSON.parse(data);
      if (!data.models || !data.models.length) {
        throw new Error(
          "error when listing gemini models, Result:" + JSON.stringify(data)
        );
      }
      return data.models.map((model) => model.name).filter(
        (model) => model.includes("gemini") || model.includes("gemma") || model.includes("embedding")
      );
    } catch (e) {
      const error = new Error(
        "error when listing gemini models, Result: " + JSON.stringify(data)
      );
      error.stack = e.stack;
      error.cause = e.cause;
      throw error;
    }
  }
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  _post(url, data, params = {}) {
    const requestUrl = this._concatUrl(url);
    for (const key in data) {
      if (data[key] === void 0) {
        delete data[key];
      }
    }
    const body = JSON.stringify(data);
    fs.writeFile("./request.json", body);
    return this._plugin.fetch(requestUrl, {
      body,
      headers: this._buildHeaders(),
      method: "POST",
      ...params
    });
  }
  _get(url) {
    const requestUrl = this._concatUrl(url);
    return this._plugin.fetch(requestUrl, {
      method: "GET",
      headers: this._buildHeaders()
    });
  }
  _concatUrl(url) {
    const apiEndPoint = this._config.apiEndpoint;
    let baseURL;
    if (apiEndPoint.endsWith("/")) {
      baseURL = new URL(apiEndPoint + url);
    } else {
      baseURL = new URL(apiEndPoint + "/" + url);
    }
    const searchParams = baseURL.searchParams;
    searchParams.set("key", this._config.apiKey);
    return baseURL.toString();
  }
  _buildHeaders() {
    return {
      /*  Authorization: `Bearer ${this._config.apiKey}`, */
      "Content-Type": "application/json"
    };
  }
  async init() {
  }
  async dispose() {
  }
};

// src/client.ts
var GeminiClient = class extends PlatformModelAndEmbeddingsClient {
  constructor(ctx, _config, clientConfig, plugin) {
    super(ctx, clientConfig);
    this._config = _config;
    this.platform = this.config.platform;
    this._requester = new GeminiRequester(
      clientConfig,
      plugin,
      this._config
    );
  }
  static {
    __name(this, "GeminiClient");
  }
  platform = "gemini";
  _requester;
  _models;
  async init() {
    await this.getModels();
  }
  async refreshModels() {
    try {
      let rawModels = await this._requester.getModels();
      if (!rawModels.length) {
        throw new ChatLunaError2(
          ChatLunaErrorCode2.MODEL_INIT_ERROR,
          new Error("No model found")
        );
      }
      rawModels = rawModels.map((model) => model.replace("models/", ""));
      const models = [];
      for (const model of rawModels) {
        const info = {
          name: model,
          maxTokens: ((model2) => {
            if (model2.includes("gemini-1.5-pro")) {
              return 1048576;
            }
            if (model2.includes("gemini-1.5-flash") || model2.includes("gemini-2.0-pro") || model2.includes("gemini-2.5-pro")) {
              return 2097152;
            }
            if (model2.includes("gemini-1.0-pro")) {
              return 30720;
            }
            return 1048576;
          })(model),
          type: model.includes("embedding") ? ModelType.embeddings : ModelType.llm,
          functionCall: !model.includes("vision"),
          supportMode: ["all"]
        };
        if (model.includes("gemini-2.5")) {
          if (!model.includes("-thinking")) {
            models.push(
              { ...info, name: model + "-no-thinking" },
              { ...info, name: model + "-thinking" },
              info
            );
          } else {
            models.push(info);
          }
        } else {
          models.push(info);
        }
      }
      return models;
    } catch (e) {
      throw new ChatLunaError2(ChatLunaErrorCode2.MODEL_INIT_ERROR, e);
    }
  }
  async getModels() {
    if (this._models) {
      return Object.values(this._models);
    }
    const models = await this.refreshModels();
    this._models = {};
    for (const model of models) {
      this._models[model.name] = model;
    }
  }
  _createModel(model) {
    const info = this._models[model];
    if (info == null) {
      throw new ChatLunaError2(ChatLunaErrorCode2.MODEL_NOT_FOUND);
    }
    if (info.type === ModelType.llm) {
      return new ChatLunaChatModel({
        modelInfo: info,
        requester: this._requester,
        model,
        modelMaxContextSize: info.maxTokens,
        maxTokenLimit: this._config.maxTokens,
        timeout: this._config.timeout,
        temperature: this._config.temperature,
        maxRetries: this._config.maxRetries,
        llmType: this.platform
      });
    }
    return new ChatLunaEmbeddings({
      client: this._requester,
      model,
      maxRetries: this._config.maxRetries
    });
  }
};

// src/index.ts
import { createLogger } from "koishi-plugin-chatluna/utils/logger";
var logger;
var reusable = true;
function apply(ctx, config) {
  const plugin = new ChatLunaPlugin(ctx, config, config.platform);
  logger = createLogger(ctx, "chatluna-gemini-adapter");
  ctx.on("ready", async () => {
    plugin.registerToService();
    await plugin.parseConfig((config2) => {
      return config2.apiKeys.map(([apiKey, apiEndpoint]) => {
        return {
          apiKey,
          apiEndpoint,
          platform: config2.platform,
          chatLimit: config2.chatTimeLimit,
          timeout: config2.timeout,
          maxRetries: config2.maxRetries,
          concurrentMaxSize: config2.chatConcurrentMaxSize
        };
      });
    });
    plugin.registerClient(
      (_, clientConfig) => new GeminiClient(ctx, config, clientConfig, plugin)
    );
    await plugin.initClients();
  });
}
__name(apply, "apply");
var Config3 = Schema.intersect([
  ChatLunaPlugin.Config,
  Schema.object({
    platform: Schema.string().default("gemini"),
    apiKeys: Schema.array(
      Schema.tuple([
        Schema.string().role("secret"),
        Schema.string().default(
          "https://generativelanguage.googleapis.com/v1beta"
        )
      ])
    ).default([["", "https://generativelanguage.googleapis.com/v1beta"]])
  }),
  Schema.object({
    maxTokens: Schema.number().min(16).max(2097e3).step(16).default(8064),
    temperature: Schema.percent().min(0).max(2).step(0.1).default(0.8),
    googleSearch: Schema.boolean().default(false),
    thinkingBudget: Schema.number().min(0).max(24576).step(16).default(4096),
    imageGeneration: Schema.boolean().default(false),
    groundingContentDisplay: Schema.boolean().default(false),
    searchThreshold: Schema.number().min(0).max(1).step(0.1).default(0.5)
  })
]).i18n({
  "zh-CN": require_zh_CN_schema(),
  "en-US": require_en_US_schema()
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
});
var inject = ["chatluna"];
var name = "chatluna-google-gemini-adapter";
export {
  Config3 as Config,
  apply,
  inject,
  logger,
  name,
  reusable
};
