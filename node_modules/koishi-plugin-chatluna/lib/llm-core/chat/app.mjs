var __defProp = Object.defineProperty;
var __name = (target, value) => __defProp(target, "name", { value, configurable: true });

// src/llm-core/chat/app.ts
import { parseRawModelName } from "koishi-plugin-chatluna/llm-core/utils/count_tokens";
import { BufferMemory } from "koishi-plugin-chatluna/llm-core/memory/langchain";
import { logger } from "koishi-plugin-chatluna";
import {
  ChatLunaError,
  ChatLunaErrorCode
} from "koishi-plugin-chatluna/utils/error";
import { KoishiChatMessageHistory } from "koishi-plugin-chatluna/llm-core/memory/message";
import { emptyEmbeddings } from "koishi-plugin-chatluna/llm-core/model/in_memory";
import {
  PlatformEmbeddingsClient,
  PlatformModelAndEmbeddingsClient,
  PlatformModelClient
} from "koishi-plugin-chatluna/llm-core/platform/client";
import {
  ChatLunaChatModel
} from "koishi-plugin-chatluna/llm-core/platform/model";
import { AIMessage } from "@langchain/core/messages";
import { getMessageContent } from "koishi-plugin-chatluna/utils/string";
var ChatInterface = class {
  constructor(ctx, input) {
    this.ctx = ctx;
    this._input = input;
  }
  static {
    __name(this, "ChatInterface");
  }
  _input;
  _chatHistory;
  _chains = {};
  _embeddings;
  _errorCountsMap = {};
  _chatCount = 0;
  async handleChatError(error, config) {
    const configMD5 = config.md5();
    if (error instanceof ChatLunaError && error.errorCode === ChatLunaErrorCode.API_UNSAFE_CONTENT) {
      throw error;
    }
    this._errorCountsMap[configMD5] = this._errorCountsMap[configMD5] ?? [];
    const errorTimes = this._errorCountsMap[configMD5];
    errorTimes.push(Date.now());
    if (errorTimes.length > config.value.maxRetries * 3) {
      this._errorCountsMap[configMD5] = errorTimes.slice(
        -config.value.maxRetries * 3
      );
    }
    const recentErrors = errorTimes.slice(-config.value.maxRetries);
    if (recentErrors.length >= config.value.maxRetries && checkRange(recentErrors, 1e3 * 60 * 20)) {
      await this.disableConfig(config);
    }
    if (error instanceof ChatLunaError) {
      throw error;
    }
    throw new ChatLunaError(ChatLunaErrorCode.UNKNOWN_ERROR, error);
  }
  async disableConfig(config) {
    const configMD5 = config.md5();
    delete this._chains[configMD5];
    delete this._errorCountsMap[configMD5];
    const service = this.ctx.chatluna.platform;
    await service.makeConfigStatus(config.value, false);
  }
  async chat(arg) {
    const [wrapper, config] = await this.createChatLunaLLMChainWrapper();
    try {
      await this.ctx.parallel(
        "chatluna/before-chat",
        arg.conversationId,
        arg.message,
        arg.variables,
        this,
        wrapper
      );
    } catch (error) {
      logger.error("Something went wrong when calling before-chat hook:");
      logger.error(error);
    }
    const additionalArgs = await this._chatHistory.getAdditionalArgs();
    if (arg.postHandler) {
      for (const key in arg.postHandler.variables) {
        arg.variables[key] = "";
      }
    }
    arg.variables = { ...additionalArgs, ...arg.variables };
    try {
      const response = await this.processChat(arg, wrapper);
      delete this._errorCountsMap[config.md5()];
      return response;
    } catch (error) {
      await this.handleChatError(error, config);
    }
  }
  async processChat(arg, wrapper) {
    const response = (await wrapper.call({
      ...arg,
      maxToken: (await this.preset)?.config?.maxOutputToken
    })).message;
    const displayResponse = new AIMessage(response);
    displayResponse.additional_kwargs = response.additional_kwargs;
    this._chatCount++;
    if (arg.postHandler) {
      const handlerResult = await this.handlePostProcessing(
        arg,
        displayResponse
      );
      displayResponse.content = handlerResult.displayContent;
      await this._chatHistory.overrideAdditionalArgs(
        handlerResult.variables
      );
    }
    const messageContent = getMessageContent(displayResponse.content);
    if (messageContent.trim().length > 0) {
      await this.chatHistory.addMessage(arg.message);
      let saveMessage = response;
      if (!this.ctx.chatluna.config.rawOnCensor) {
        saveMessage = displayResponse;
      }
      await this.chatHistory.addMessage(saveMessage);
    }
    this.ctx.parallel(
      "chatluna/after-chat",
      arg.conversationId,
      arg.message,
      displayResponse,
      { ...arg.variables, chatCount: this._chatCount },
      this,
      wrapper
    );
    return { message: displayResponse };
  }
  async handlePostProcessing(arg, message) {
    logger.debug(`original content: %c`, message.content);
    return await arg.postHandler.handler(
      arg.session,
      getMessageContent(message.content)
    );
  }
  async createChatLunaLLMChainWrapper() {
    const service = this.ctx.chatluna.platform;
    const [llmPlatform, llmModelName] = parseRawModelName(this._input.model);
    const currentLLMConfig = await service.randomConfig(llmPlatform);
    if (this._chains[currentLLMConfig.md5()]) {
      return [this._chains[currentLLMConfig.md5()], currentLLMConfig];
    }
    let embeddings;
    let llm;
    let modelInfo;
    let historyMemory;
    try {
      embeddings = await this._initEmbeddings(service);
    } catch (error) {
      if (error instanceof ChatLunaError) {
        throw error;
      }
      throw new ChatLunaError(
        ChatLunaErrorCode.EMBEDDINGS_INIT_ERROR,
        error
      );
    }
    try {
      ;
      [llm, modelInfo] = await this._initModel(
        service,
        currentLLMConfig.value,
        llmModelName
      );
    } catch (error) {
      if (error instanceof ChatLunaError) {
        throw error;
      }
      throw new ChatLunaError(ChatLunaErrorCode.MODEL_INIT_ERROR, error);
    }
    try {
      await this._createChatHistory();
    } catch (error) {
      if (error instanceof ChatLunaError) {
        throw error;
      }
      throw new ChatLunaError(
        ChatLunaErrorCode.CHAT_HISTORY_INIT_ERROR,
        error
      );
    }
    try {
      historyMemory = this._createHistoryMemory();
    } catch (error) {
      if (error instanceof ChatLunaError) {
        throw error;
      }
      throw new ChatLunaError(ChatLunaErrorCode.UNKNOWN_ERROR, error);
    }
    const chatChain = await service.createChatChain(this._input.chatMode, {
      botName: this._input.botName,
      model: llm,
      embeddings,
      historyMemory,
      preset: this._input.preset,
      vectorStoreName: this._input.vectorStoreName,
      supportChatChain: this._supportChatMode(modelInfo)
    });
    this._chains[currentLLMConfig.md5()] = chatChain;
    this._embeddings = embeddings;
    return [chatChain, currentLLMConfig];
  }
  get chatHistory() {
    return this._chatHistory;
  }
  get chatMode() {
    return this._input.chatMode;
  }
  get embeddings() {
    return this._embeddings;
  }
  get preset() {
    return this._input.preset();
  }
  async delete(ctx, room) {
    await this.clearChatHistory();
    for (const chain of Object.values(this._chains)) {
      await chain.model.clearContext(room.conversationId);
    }
    this._chains = {};
    await ctx.database.remove("chathub_conversation", {
      id: room.conversationId
    });
    await ctx.database.remove("chathub_room", {
      roomId: room.roomId
    });
    await ctx.database.remove("chathub_room_member", {
      roomId: room.roomId
    });
    await ctx.database.remove("chathub_room_group_member", {
      roomId: room.roomId
    });
    await ctx.database.remove("chathub_user", {
      defaultRoomId: room.roomId
    });
    await ctx.database.remove("chathub_message", {
      conversation: room.conversationId
    });
  }
  async clearChatHistory() {
    if (this._chatHistory == null) {
      await this._createChatHistory();
    }
    await this.ctx.root.parallel(
      "chatluna/clear-chat-history",
      this._input.conversationId,
      this
    );
    await this._chatHistory.clear();
    for (const chain of Object.values(this._chains)) {
      await chain.model.clearContext(this._input.conversationId);
    }
  }
  async _initEmbeddings(service) {
    if (this._input.embeddings == null || this._input.embeddings.length < 1 || this._input.embeddings === "无") {
      if (this._input.vectorStoreName != null && this._input.vectorStoreName?.length > 0 && this._input.vectorStoreName !== "无") {
        logger.warn(
          "Embeddings are empty, falling back to fake embeddings. Try check your config."
        );
      }
      return emptyEmbeddings;
    }
    const [platform, modelName] = parseRawModelName(this._input.embeddings);
    logger.info(`init embeddings for %c`, this._input.embeddings);
    const client = await service.randomClient(platform);
    if (client == null || client instanceof PlatformModelClient) {
      logger.warn(
        `Platform ${platform} is not supported, falling back to fake embeddings`
      );
      return emptyEmbeddings;
    }
    if (client instanceof PlatformEmbeddingsClient) {
      return client.createModel(modelName);
    } else if (client instanceof PlatformModelAndEmbeddingsClient) {
      const model = client.createModel(modelName);
      if (model instanceof ChatLunaChatModel) {
        logger.warn(
          `Model ${modelName} is not an embeddings model, falling back to fake embeddings`
        );
        return emptyEmbeddings;
      }
      return model;
    }
  }
  async _initModel(service, config, llmModelName) {
    const platform = await service.getClient(config);
    const llmInfo = (await platform.getModels()).find(
      (model) => model.name === llmModelName
    );
    const llmModel = platform.createModel(llmModelName);
    if (llmModel instanceof ChatLunaChatModel) {
      return [llmModel, llmInfo];
    }
  }
  _supportChatMode(modelInfo) {
    if (
      // default check
      !modelInfo.supportMode?.includes(this._input.chatMode) && // all
      !modelInfo.supportMode?.includes("all") || // func call with plugin
      !modelInfo.functionCall && this._input.chatMode === "plugin"
    ) {
      logger.warn(
        `Chat mode ${this._input.chatMode} is not supported by model ${this._input.model}`
      );
      return false;
    }
    return true;
  }
  async _createChatHistory() {
    if (this._chatHistory != null) {
      return this._chatHistory;
    }
    this._chatHistory = new KoishiChatMessageHistory(
      this.ctx,
      this._input.conversationId,
      this._input.maxMessagesCount
    );
    await this._chatHistory.loadConversation();
    return this._chatHistory;
  }
  _createHistoryMemory() {
    return new BufferMemory({
      returnMessages: true,
      inputKey: "input",
      outputKey: "output",
      chatHistory: this._chatHistory,
      humanPrefix: "user",
      aiPrefix: this._input.botName
    });
  }
};
function checkRange(times, delayTime) {
  const first = times[0];
  const last = times[times.length - 1];
  return last - first < delayTime;
}
__name(checkRange, "checkRange");
export {
  ChatInterface
};
