import { Embeddings } from '@langchain/core/embeddings';
import { PromptTemplate } from '@langchain/core/prompts';
import { ChainValues } from '@langchain/core/utils/types';
import { ChatLunaLLMCallArg, ChatLunaLLMChain, ChatLunaLLMChainWrapper } from 'koishi-plugin-chatluna/llm-core/chain/base';
import { ChatLunaChatModel } from 'koishi-plugin-chatluna/llm-core/platform/model';
import { BufferMemory } from 'koishi-plugin-chatluna/llm-core/memory/langchain';
import { PresetTemplate } from 'koishi-plugin-chatluna/llm-core/prompt';
import { ChatLunaTool } from 'koishi-plugin-chatluna/llm-core/platform/types';
import { SummaryType } from '../types';
import { PresetFormatService } from 'koishi-plugin-chatluna/services/chat';
export interface ChatLunaBrowsingChainInput {
    botName: string;
    preset: () => Promise<PresetTemplate>;
    embeddings: Embeddings;
    historyMemory: BufferMemory;
    summaryType: SummaryType;
    thoughtMessage: boolean;
    summaryModel: ChatLunaChatModel;
    searchPrompt: string;
    newQuestionPrompt: string;
    contextualCompressionPrompt?: string;
    searchFailedPrompt: string;
    variableService: PresetFormatService;
}
export declare class ChatLunaBrowsingChain extends ChatLunaLLMChainWrapper implements ChatLunaBrowsingChainInput {
    botName: string;
    embeddings: Embeddings;
    chain: ChatLunaLLMChain;
    historyMemory: BufferMemory;
    preset: () => Promise<PresetTemplate>;
    formatQuestionChain: ChatLunaLLMChain;
    contextualCompressionChain?: ChatLunaLLMChain;
    tools: ChatLunaToolWrapper[];
    newQuestionPrompt: string;
    responsePrompt: PromptTemplate;
    summaryType: SummaryType;
    summaryModel: ChatLunaChatModel;
    contextualCompressionPrompt: string;
    variableService: PresetFormatService;
    thoughtMessage: boolean;
    searchPrompt: string;
    searchFailedPrompt: string;
    constructor({ botName, embeddings, historyMemory, chain, searchFailedPrompt, tools, formatQuestionChain, summaryType, thoughtMessage, searchPrompt, summaryModel, contextualCompressionChain }: ChatLunaBrowsingChainInput & {
        chain: ChatLunaLLMChain;
        formatQuestionChain: ChatLunaLLMChain;
        tools: ChatLunaToolWrapper[];
        searchPrompt: string;
        contextualCompressionChain?: ChatLunaLLMChain;
    });
    static fromLLMAndTools(llm: ChatLunaChatModel, tools: ChatLunaToolWrapper[], { botName, embeddings, summaryModel, historyMemory, preset, thoughtMessage, searchPrompt, newQuestionPrompt, summaryType, searchFailedPrompt, variableService, contextualCompressionPrompt }: ChatLunaBrowsingChainInput): ChatLunaBrowsingChain;
    private _selectTool;
    call({ message, stream, events, conversationId, session, variables, maxToken, signal }: ChatLunaLLMCallArg): Promise<ChainValues>;
    private parseSearchAction;
    private _search;
    get model(): ChatLunaChatModel;
}
interface ChatLunaToolWrapper {
    name: string;
    tool: ChatLunaTool;
}
export declare function chunkArray<T>(array: T[], size: number): T[][];
export {};
